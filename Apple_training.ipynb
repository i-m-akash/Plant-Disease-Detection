{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models , layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE=256\n",
    "BATCH_SIZE=8\n",
    "CHANNELS=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9714 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset =tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"Apple\",\n",
    "    shuffle=True,\n",
    "    image_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
    "    batch_size = BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple___Apple_scab',\n",
       " 'Apple___Black_rot',\n",
       " 'Apple___Cedar_apple_rust',\n",
       " 'Apple___healthy']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = dataset.class_names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1215"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_partitions_tf(ds,train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=1000):\n",
    "\n",
    "  ds_size =len(ds)\n",
    "\n",
    "  if shuffle:\n",
    "    ds=ds.shuffle(shuffle_size)\n",
    "\n",
    "  train_size = int(train_split*ds_size)\n",
    "  val_size = int(val_split*ds_size)\n",
    "\n",
    "  train_ds = ds.take(train_size)\n",
    "\n",
    "  val_ds=ds.skip(train_size).take(val_size)\n",
    "  test_ds=ds.skip(train_size).skip(val_size)\n",
    "\n",
    "\n",
    "  return train_ds ,val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "972"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds=train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds=val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_ds=test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_and_rescale = tf.keras.Sequential([\n",
    "    layers.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    layers.Rescaling(1.0/255)\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "     layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "     layers.RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rekha\\OneDrive\\Desktop\\Plant Disease Detection\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "input_shape=(BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
    "n_classes=4\n",
    "model1=models.Sequential([\n",
    "    resize_and_rescale,\n",
    "    data_augmentation,\n",
    "\n",
    "    layers.Conv2D(32,(3,3),activation='relu',input_shape=input_shape),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "\n",
    "    layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "\n",
    "\n",
    "    layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "\n",
    "\n",
    "    layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "\n",
    "    layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "\n",
    "    layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "\n",
    "\n",
    "    layers.Flatten(),\n",
    "\n",
    "    layers.Dense(64,activation='relu'),\n",
    "    layers.Dense(n_classes,activation='softmax')\n",
    "])\n",
    "model1.build(input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Model.summary of <Sequential name=sequential_2, built=True>>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('./apple_model.keras',\n",
    "    verbose=1,\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507ms/step - accuracy: 0.5125 - loss: 1.0283\n",
      "Epoch 1: val_accuracy improved from -inf to 0.85537, saving model to ./apple_model.keras\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m577s\u001b[0m 544ms/step - accuracy: 0.5126 - loss: 1.0280 - val_accuracy: 0.8554 - val_loss: 0.3581\n",
      "Epoch 2/15\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498ms/step - accuracy: 0.8847 - loss: 0.2970\n",
      "Epoch 2: val_accuracy did not improve from 0.85537\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m501s\u001b[0m 513ms/step - accuracy: 0.8847 - loss: 0.2970 - val_accuracy: 0.8502 - val_loss: 0.4058\n",
      "Epoch 3/15\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - accuracy: 0.9343 - loss: 0.1890\n",
      "Epoch 3: val_accuracy improved from 0.85537 to 0.93905, saving model to ./apple_model.keras\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m500s\u001b[0m 514ms/step - accuracy: 0.9343 - loss: 0.1889 - val_accuracy: 0.9390 - val_loss: 0.1576\n",
      "Epoch 4/15\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523ms/step - accuracy: 0.9631 - loss: 0.1118\n",
      "Epoch 4: val_accuracy did not improve from 0.93905\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m532s\u001b[0m 546ms/step - accuracy: 0.9631 - loss: 0.1118 - val_accuracy: 0.9380 - val_loss: 0.1858\n",
      "Epoch 5/15\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step - accuracy: 0.9568 - loss: 0.1274\n",
      "Epoch 5: val_accuracy improved from 0.93905 to 0.97727, saving model to ./apple_model.keras\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m480s\u001b[0m 494ms/step - accuracy: 0.9568 - loss: 0.1273 - val_accuracy: 0.9773 - val_loss: 0.0745\n",
      "Epoch 6/15\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - accuracy: 0.9673 - loss: 0.0941\n",
      "Epoch 6: val_accuracy did not improve from 0.97727\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 439ms/step - accuracy: 0.9673 - loss: 0.0941 - val_accuracy: 0.8760 - val_loss: 0.3295\n",
      "Epoch 7/15\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - accuracy: 0.9739 - loss: 0.0785\n",
      "Epoch 7: val_accuracy improved from 0.97727 to 0.98037, saving model to ./apple_model.keras\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m391s\u001b[0m 402ms/step - accuracy: 0.9739 - loss: 0.0785 - val_accuracy: 0.9804 - val_loss: 0.0780\n",
      "Epoch 8/15\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - accuracy: 0.9633 - loss: 0.1068\n",
      "Epoch 8: val_accuracy did not improve from 0.98037\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 431ms/step - accuracy: 0.9633 - loss: 0.1068 - val_accuracy: 0.9494 - val_loss: 0.1153\n",
      "Epoch 9/15\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516ms/step - accuracy: 0.9815 - loss: 0.0573\n",
      "Epoch 9: val_accuracy did not improve from 0.98037\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m520s\u001b[0m 535ms/step - accuracy: 0.9815 - loss: 0.0573 - val_accuracy: 0.9742 - val_loss: 0.0758\n",
      "Epoch 10/15\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616ms/step - accuracy: 0.9828 - loss: 0.0536\n",
      "Epoch 10: val_accuracy improved from 0.98037 to 0.98657, saving model to ./apple_model.keras\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 635ms/step - accuracy: 0.9828 - loss: 0.0536 - val_accuracy: 0.9866 - val_loss: 0.0453\n",
      "Epoch 11/15\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609ms/step - accuracy: 0.9854 - loss: 0.0473\n",
      "Epoch 11: val_accuracy did not improve from 0.98657\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m612s\u001b[0m 629ms/step - accuracy: 0.9854 - loss: 0.0473 - val_accuracy: 0.9845 - val_loss: 0.0390\n",
      "Epoch 12/15\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607ms/step - accuracy: 0.9882 - loss: 0.0364\n",
      "Epoch 12: val_accuracy did not improve from 0.98657\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m609s\u001b[0m 626ms/step - accuracy: 0.9882 - loss: 0.0364 - val_accuracy: 0.9597 - val_loss: 0.1406\n",
      "Epoch 13/15\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569ms/step - accuracy: 0.9818 - loss: 0.0583\n",
      "Epoch 13: val_accuracy did not improve from 0.98657\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m569s\u001b[0m 585ms/step - accuracy: 0.9818 - loss: 0.0583 - val_accuracy: 0.9618 - val_loss: 0.1201\n",
      "Epoch 14/15\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step - accuracy: 0.9809 - loss: 0.0561\n",
      "Epoch 14: val_accuracy did not improve from 0.98657\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m502s\u001b[0m 516ms/step - accuracy: 0.9809 - loss: 0.0561 - val_accuracy: 0.9866 - val_loss: 0.0401\n",
      "Epoch 15/15\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502ms/step - accuracy: 0.9879 - loss: 0.0381\n",
      "Epoch 15: val_accuracy did not improve from 0.98657\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m501s\u001b[0m 516ms/step - accuracy: 0.9879 - loss: 0.0381 - val_accuracy: 0.9545 - val_loss: 0.1342\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=15\n",
    "history=model1.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    verbose=1,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 102ms/step - accuracy: 0.9602 - loss: 0.0928\n"
     ]
    }
   ],
   "source": [
    "scores=model1.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 1, 'epochs': 15, 'steps': 972}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6904761791229248,\n",
       " 0.900772213935852,\n",
       " 0.9437580704689026,\n",
       " 0.9651222825050354,\n",
       " 0.9630630612373352,\n",
       " 0.970141589641571,\n",
       " 0.976962685585022,\n",
       " 0.9676962494850159,\n",
       " 0.9796653985977173,\n",
       " 0.9821106791496277,\n",
       " 0.9790219068527222,\n",
       " 0.9876447916030884,\n",
       " 0.9841699004173279,\n",
       " 0.9849420785903931,\n",
       " 0.9855855703353882]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.85537189245224,\n",
       " 0.8502066135406494,\n",
       " 0.9390496015548706,\n",
       " 0.9380165338516235,\n",
       " 0.9772727489471436,\n",
       " 0.8760330677032471,\n",
       " 0.98037189245224,\n",
       " 0.9493801593780518,\n",
       " 0.9741735458374023,\n",
       " 0.9865702390670776,\n",
       " 0.9845041036605835,\n",
       " 0.9597107172012329,\n",
       " 0.961776852607727,\n",
       " 0.9865702390670776,\n",
       " 0.9545454382896423]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first image to predict:\n",
      "first image's actual label: Apple___Cedar_apple_rust\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step\n",
      "[6.5581644e-06 2.6280975e-06 9.9999082e-01 1.5671032e-11]\n",
      "2\n",
      "Apple___Cedar_apple_rust\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for images_batch,label_batch in test_ds.take(1):\n",
    "  first_image = images_batch[0].numpy().astype('uint8')\n",
    "  first_label = label_batch[0].numpy()\n",
    "\n",
    "  print('first image to predict:')\n",
    "\n",
    "  #print(\"first image's actual label:\",first_label)\n",
    "  print(\"first image's actual label:\",class_names[first_label])\n",
    "  batch_prediction = model1.predict(images_batch)\n",
    "  print(batch_prediction[0])\n",
    "  print(np.argmax(batch_prediction[0]))\n",
    "  print(class_names[np.argmax(batch_prediction[0])])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,img):\n",
    "  img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())\n",
    "  img_array = tf.expand_dims(img_array,0)# Create a batch\n",
    "\n",
    "  predictions = model.predict(img_array)\n",
    "\n",
    "  predicted_class = class_names[np.argmax(predictions[0])]\n",
    "  confidence = round(100* (np.max(predictions[0])),2)\n",
    "  return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step\n",
      "Apple___Black_rot\n",
      "100.0\n",
      "Apple___Black_rot\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Apple___Black_rot\n",
      "100.0\n",
      "Apple___Black_rot\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Apple___healthy\n",
      "99.43\n",
      "Apple___healthy\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Apple___Apple_scab\n",
      "99.84\n",
      "Apple___Apple_scab\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Apple___Cedar_apple_rust\n",
      "100.0\n",
      "Apple___Cedar_apple_rust\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Apple___Apple_scab\n",
      "91.68\n",
      "Apple___Apple_scab\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Apple___Apple_scab\n",
      "99.93\n",
      "Apple___Apple_scab\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Apple___Apple_scab\n",
      "94.16\n",
      "Apple___healthy\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} slice index 8 of dimension 0 out of bounds. [Op:StridedSlice] name: strided_slice/",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m test_ds\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      2\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m9\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m     predicted_class, confidence\u001b[38;5;241m=\u001b[39mpredict(model1,\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(predicted_class)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(confidence)\n",
      "File \u001b[1;32mc:\\Users\\rekha\\OneDrive\\Desktop\\Plant Disease Detection\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\rekha\\OneDrive\\Desktop\\Plant Disease Detection\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:5983\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   5981\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m   5982\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 5983\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} slice index 8 of dimension 0 out of bounds. [Op:StridedSlice] name: strided_slice/"
     ]
    }
   ],
   "source": [
    "\n",
    "for images, labels in test_ds.take(1):\n",
    "  for i in range(9):\n",
    "\n",
    "    predicted_class, confidence=predict(model1,images[i].numpy())\n",
    "    print(predicted_class)\n",
    "    print(confidence)\n",
    "    actual_class = class_names[labels[i]]\n",
    "    print(actual_class)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
