{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models , layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE=256\n",
    "BATCH_SIZE=8\n",
    "CHANNELS=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9027 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset =tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"Grape\",\n",
    "    shuffle=True,\n",
    "    image_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
    "    batch_size = BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Grape___Black_rot',\n",
       " 'Grape___Esca_(Black_Measles)',\n",
       " 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)',\n",
       " 'Grape___healthy']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = dataset.class_names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1129"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_partitions_tf(ds,train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=1000):\n",
    "\n",
    "  ds_size =len(ds)\n",
    "\n",
    "  if shuffle:\n",
    "    ds=ds.shuffle(shuffle_size)\n",
    "\n",
    "  train_size = int(train_split*ds_size)\n",
    "  val_size = int(val_split*ds_size)\n",
    "\n",
    "  train_ds = ds.take(train_size)\n",
    "\n",
    "  val_ds=ds.skip(train_size).take(val_size)\n",
    "  test_ds=ds.skip(train_size).skip(val_size)\n",
    "\n",
    "\n",
    "  return train_ds ,val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "903"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds=train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds=val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_ds=test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_and_rescale = tf.keras.Sequential([\n",
    "    layers.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    layers.Rescaling(1.0/255)\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "     layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "     layers.RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rekha\\OneDrive\\Desktop\\Plant Disease Detection\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "input_shape=(BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
    "n_classes=4\n",
    "model1=models.Sequential([\n",
    "    resize_and_rescale,\n",
    "    data_augmentation,\n",
    "\n",
    "    layers.Conv2D(32,(3,3),activation='relu',input_shape=input_shape),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "\n",
    "    layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "\n",
    "\n",
    "    layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "\n",
    "\n",
    "    layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "\n",
    "    layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "\n",
    "    layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "\n",
    "\n",
    "    layers.Flatten(),\n",
    "\n",
    "    layers.Dense(64,activation='relu'),\n",
    "    layers.Dense(n_classes,activation='softmax')\n",
    "])\n",
    "model1.build(input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Model.summary of <Sequential name=sequential_2, built=True>>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('./grape_model.keras',\n",
    "    verbose=1,\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594ms/step - accuracy: 0.4801 - loss: 1.0686\n",
      "Epoch 1: val_accuracy improved from -inf to 0.57478, saving model to ./grape_model.keras\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m703s\u001b[0m 717ms/step - accuracy: 0.4803 - loss: 1.0683 - val_accuracy: 0.5748 - val_loss: 1.8494\n",
      "Epoch 2/10\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523ms/step - accuracy: 0.8134 - loss: 0.4723\n",
      "Epoch 2: val_accuracy improved from 0.57478 to 0.81473, saving model to ./grape_model.keras\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m511s\u001b[0m 565ms/step - accuracy: 0.8134 - loss: 0.4723 - val_accuracy: 0.8147 - val_loss: 0.5033\n",
      "Epoch 3/10\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619ms/step - accuracy: 0.9133 - loss: 0.2376\n",
      "Epoch 3: val_accuracy did not improve from 0.81473\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m574s\u001b[0m 634ms/step - accuracy: 0.9133 - loss: 0.2376 - val_accuracy: 0.6618 - val_loss: 1.5084\n",
      "Epoch 4/10\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step - accuracy: 0.9339 - loss: 0.1767\n",
      "Epoch 4: val_accuracy improved from 0.81473 to 0.92299, saving model to ./grape_model.keras\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 455ms/step - accuracy: 0.9339 - loss: 0.1767 - val_accuracy: 0.9230 - val_loss: 0.1772\n",
      "Epoch 5/10\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step - accuracy: 0.9478 - loss: 0.1462\n",
      "Epoch 5: val_accuracy did not improve from 0.92299\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 448ms/step - accuracy: 0.9478 - loss: 0.1462 - val_accuracy: 0.9230 - val_loss: 0.1975\n",
      "Epoch 6/10\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - accuracy: 0.9521 - loss: 0.1177\n",
      "Epoch 6: val_accuracy improved from 0.92299 to 0.93750, saving model to ./grape_model.keras\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m391s\u001b[0m 433ms/step - accuracy: 0.9521 - loss: 0.1177 - val_accuracy: 0.9375 - val_loss: 0.1356\n",
      "Epoch 7/10\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - accuracy: 0.9594 - loss: 0.1098\n",
      "Epoch 7: val_accuracy did not improve from 0.93750\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 474ms/step - accuracy: 0.9594 - loss: 0.1098 - val_accuracy: 0.9319 - val_loss: 0.1703\n",
      "Epoch 8/10\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step - accuracy: 0.9607 - loss: 0.1009\n",
      "Epoch 8: val_accuracy did not improve from 0.93750\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 491ms/step - accuracy: 0.9607 - loss: 0.1009 - val_accuracy: 0.9085 - val_loss: 0.2137\n",
      "Epoch 9/10\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672ms/step - accuracy: 0.9734 - loss: 0.0775\n",
      "Epoch 9: val_accuracy improved from 0.93750 to 0.97098, saving model to ./grape_model.keras\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m639s\u001b[0m 708ms/step - accuracy: 0.9734 - loss: 0.0775 - val_accuracy: 0.9710 - val_loss: 0.0745\n",
      "Epoch 10/10\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768ms/step - accuracy: 0.9783 - loss: 0.0621\n",
      "Epoch 10: val_accuracy improved from 0.97098 to 0.98214, saving model to ./grape_model.keras\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m749s\u001b[0m 830ms/step - accuracy: 0.9783 - loss: 0.0621 - val_accuracy: 0.9821 - val_loss: 0.0416\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=10\n",
    "history=model1.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    verbose=1,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 155ms/step - accuracy: 0.9794 - loss: 0.0580\n"
     ]
    }
   ],
   "source": [
    "scores=model1.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 1, 'epochs': 10, 'steps': 903}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6385926008224487,\n",
       " 0.8343260884284973,\n",
       " 0.9188253283500671,\n",
       " 0.9351710677146912,\n",
       " 0.9516553282737732,\n",
       " 0.9584429860115051,\n",
       " 0.964676558971405,\n",
       " 0.964953601360321,\n",
       " 0.976035475730896,\n",
       " 0.9747887253761292]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5747767686843872,\n",
       " 0.8147321343421936,\n",
       " 0.6618303656578064,\n",
       " 0.9229910969734192,\n",
       " 0.9229910969734192,\n",
       " 0.9375,\n",
       " 0.9319196343421936,\n",
       " 0.9084821343421936,\n",
       " 0.9709821343421936,\n",
       " 0.9821428656578064]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first image to predict:\n",
      "first image's actual label: Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "[2.052342e-02 9.958733e-05 9.777624e-01 1.614606e-03]\n",
      "2\n",
      "Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for images_batch,label_batch in test_ds.take(1):\n",
    "  first_image = images_batch[0].numpy().astype('uint8')\n",
    "  first_label = label_batch[0].numpy()\n",
    "\n",
    "  print('first image to predict:')\n",
    "\n",
    "  #print(\"first image's actual label:\",first_label)\n",
    "  print(\"first image's actual label:\",class_names[first_label])\n",
    "  batch_prediction = model1.predict(images_batch)\n",
    "  print(batch_prediction[0])\n",
    "  print(np.argmax(batch_prediction[0]))\n",
    "  print(class_names[np.argmax(batch_prediction[0])])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,img):\n",
    "  img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())\n",
    "  img_array = tf.expand_dims(img_array,0)# Create a batch\n",
    "\n",
    "  predictions = model.predict(img_array)\n",
    "\n",
    "  predicted_class = class_names[np.argmax(predictions[0])]\n",
    "  confidence = round(100* (np.max(predictions[0])),2)\n",
    "  return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 857ms/step\n",
      "Grape___Black_rot\n",
      "99.98\n",
      "Grape___Black_rot\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
      "Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\n",
      "99.5\n",
      "Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "Grape___healthy\n",
      "99.8\n",
      "Grape___healthy\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Grape___healthy\n",
      "100.0\n",
      "Grape___healthy\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n",
      "Grape___Esca_(Black_Measles)\n",
      "99.99\n",
      "Grape___Esca_(Black_Measles)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Grape___healthy\n",
      "100.0\n",
      "Grape___healthy\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Grape___Esca_(Black_Measles)\n",
      "100.0\n",
      "Grape___Esca_(Black_Measles)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Grape___Esca_(Black_Measles)\n",
      "99.99\n",
      "Grape___Esca_(Black_Measles)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} slice index 8 of dimension 0 out of bounds. [Op:StridedSlice] name: strided_slice/",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m test_ds\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      2\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m9\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m     predicted_class, confidence\u001b[38;5;241m=\u001b[39mpredict(model1,\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(predicted_class)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(confidence)\n",
      "File \u001b[1;32mc:\\Users\\rekha\\OneDrive\\Desktop\\Plant Disease Detection\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\rekha\\OneDrive\\Desktop\\Plant Disease Detection\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:5983\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   5981\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m   5982\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 5983\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} slice index 8 of dimension 0 out of bounds. [Op:StridedSlice] name: strided_slice/"
     ]
    }
   ],
   "source": [
    "\n",
    "for images, labels in test_ds.take(1):\n",
    "  for i in range(9):\n",
    "\n",
    "    predicted_class, confidence=predict(model1,images[i].numpy())\n",
    "    print(predicted_class)\n",
    "    print(confidence)\n",
    "    actual_class = class_names[labels[i]]\n",
    "    print(actual_class)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
